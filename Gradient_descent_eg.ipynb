{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNmy8YEHn0JnnHj7oaEihGR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhangling297/MAT_CS_599_deepLearningClassPracitices/blob/main/Gradient_descent_eg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ED-zGOA2jBnQ"
      },
      "outputs": [],
      "source": [
        "#Create dataframe\n",
        "import pandas as pd\n",
        "\n",
        "x = [1,2,3,4]\n",
        "y = [6,7,10,15]\n",
        "\n",
        "data = {'x':x, 'y':y}\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "#Fit the model to the data\n",
        "model.fit(df[['x']], df['y'])\n",
        "\n",
        "#Generate x-values for the regression line to predict\n",
        "x_pred = np.linspace(0, 5, 500).reshape(-1, 1) # Fixed: changed Linspace to linspace\n",
        "#the trained model (model was trained on the full df_heart_disease)\n",
        "y_pred = model.predict(x_pred)\n",
        "\n",
        "#Create the plot\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(df['x'], df['y'], label='Origninal Data')\n",
        "\n",
        "#Plot the regression line\n",
        "plt.plot(x_pred, y_pred, color='red', linestyle='--', label='Linear Regression Line') # Fixed: changed llinestyle to linestyle\n",
        "\n",
        "#Add labels and title\n",
        "plt.xlabel('x') # Fixed: changed xlable to xlabel\n",
        "plt.ylabel('y')\n",
        "plt.title('Linear Regression Fit')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "#SHow the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L78G_TRYj0mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define loss function\n",
        "def calculate_loss(x,y,w,b):\n",
        "  return 0.5*((y-(w*x+b))**2)"
      ],
      "metadata": {
        "id": "pfGBST4gmcOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define cost function\n",
        "def calculate_cost(df,w,b):\n",
        "  total_cost=0\n",
        "  for _, row in df.iterrows():\n",
        "    total_cost+=calculate_loss(row['x'], row['y'], w,b)\n",
        "  return total_cost / len(df)"
      ],
      "metadata": {
        "id": "W34g5rq1muo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define gradient function\n",
        "def calculate_gradient_w(df, w, b):\n",
        "  dj_dw=0\n",
        "  for _, row in df.iterrows():\n",
        "    dj_dw += ( w * row['x'] + b - row['y']) * row['x'] # Fixed: Changed df_dw to dj_dw\n",
        "  return dj_dw / len(df)\n",
        "\n",
        "def calculate_gradient_b(df, w, b): # Fixed: Changed calcualte_gradient_b to calculate_gradient_b\n",
        "  dj_db = 0\n",
        "  for _, row in df.iterrows():\n",
        "    dj_db += (w * row['x'] + b - row['y'])\n",
        "  return dj_db / len(df)"
      ],
      "metadata": {
        "id": "mntsPPP5nTXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot cost against parameter values to observe how gradient descent is finding the opimal values\n",
        "def plot_cost_against_parameters(w_vals, b_vals, cost_vals):\n",
        "  plt.figure(figsize=(8,6))\n",
        "\n",
        "  # Subplot 1: Cost Vs . w\n",
        "  plt.subplot(1,2,1) # 1 row, 2 columns, first plot)\n",
        "  plt.plot(w_vals, cost_vals, color='navy')\n",
        "  plt.scatter(w_vals, cost_vals, color='gold',s=12)\n",
        "  plt.xlabel('w values')\n",
        "  plt.ylabel('Cost')\n",
        "  plt.title('Cost Vs. w')\n",
        "  plt.grid(True) # Fixed: Changed plt.grad to plt.grid\n",
        "\n",
        "  # Subplot 2: Cost Vs. b\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(b_vals, cost_vals, color='navy')\n",
        "  plt.scatter(b_vals, cost_vals, color='gold', s=12)\n",
        "  plt.xlabel('b values') # Fixed: Changed plt.xlable to plt.xlabel\n",
        "  plt.ylabel('Cost')\n",
        "  plt.title('Cost Vs. b')\n",
        "  plt.grid(True)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "DcN-6F5Rox4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize parameter values, learning rate, and number of steps we would like to try\n",
        "w=b=1\n",
        "alpha = 0.1\n",
        "n_iterations = 1000 # Fixed: Changed 1,000 to 1000\n",
        "\n",
        "w_vals = []\n",
        "b_vals = []\n",
        "cost_vals = []\n",
        "\n",
        "#run the algorithm for x steps\n",
        "for i in range(n_iterations):\n",
        "  current_cost = calculate_cost(df,w,b)\n",
        "  current_gradient_w = calculate_gradient_w(df,w,b)\n",
        "  current_gradient_b = calculate_gradient_b(df,w,b)\n",
        "\n",
        "  # Save the values to plot later\n",
        "  w_vals.append(w)\n",
        "  b_vals.append(b)\n",
        "  cost_vals.append(current_cost)\n",
        "\n",
        "  #Print all values at each step of the process:\n",
        "  print(f'{i+1}: w={round(w,4)}, b={round(b,4)}, Cost={round(current_cost,4)}') # Fixed: f-string syntax\n",
        "\n",
        "  # Update parameters each iteration except the final one\n",
        "  if i < (n_iterations-1):\n",
        "    w-=alpha*current_gradient_w\n",
        "    b -= alpha*current_gradient_b # Fixed: Changed b_ to b -=\n",
        "  print('------------')\n",
        "  print(f'Final parameter values: w={round(w,4)}, b={round(b,4)}') # Fixed: f-string syntax and typo 'valus'\n",
        "  print('-------------')\n",
        "  print()\n",
        "\n",
        "  plot_cost_against_parameters(w_vals, b_vals, cost_vals) # Fixed: Changed print_cost_against_parameters to plot_cost_against_parameters"
      ],
      "metadata": {
        "id": "QK9Vcxl9qugF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c049375a"
      },
      "source": [
        "# Initialize parameter values, learning rate, and number of steps we would like to try\n",
        "w=b=1\n",
        "alpha = 0.1\n",
        "n_iterations = 1000 # Fixed: Changed 1,000 to 1000\n",
        "\n",
        "w_vals = []\n",
        "b_vals = []\n",
        "cost_vals = []\n",
        "\n",
        "#run the algorithm for x steps\n",
        "for i in range(n_iterations):\n",
        "  current_cost = calculate_cost(df,w,b)\n",
        "  current_gradient_w = calculate_gradient_w(df,w,b)\n",
        "  current_gradient_b = calculate_gradient_b(df,w,b)\n",
        "\n",
        "  # Save the values to plot later\n",
        "  w_vals.append(w)\n",
        "  b_vals.append(b)\n",
        "  cost_vals.append(current_cost)\n",
        "\n",
        "  #Print all values at each step of the process:\n",
        "  print(f'{i+1}: w={round(w,4)}, b={round(b,4)}, Cost={round(current_cost,4)}') # Fixed: f-string syntax\n",
        "\n",
        "  # Update parameters each iteration except the final one\n",
        "  if i < (n_iterations-1):\n",
        "    w-=alpha*current_gradient_w\n",
        "    b -= alpha*current_gradient_b # Fixed: Changed b_ to b -=\n",
        "  print('------------')\n",
        "  print(f'Final parameter values: w={round(w,4)}, b={round(b,4)}') # Fixed: f-string syntax and typo 'valus'\n",
        "  print('-------------')\n",
        "  print()\n",
        "\n",
        "  plot_cost_against_parameters(w_vals, b_vals, cost_vals) # Fixed: Changed print_cost_against_parameters to plot_cost_against_parameters"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}